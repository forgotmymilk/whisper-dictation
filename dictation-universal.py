#!/usr/bin/env python3
"""
Universal Whisper Dictation - Portable & User-Friendly

Features:
- Chinese/English/Mixed input with smart formatting
- Auto punctuation for both languages
- Device auto-detection (GPU/CPU)
- Portable configuration
- Easy setup for non-technical users

Usage:
    python dictation-universal.py
"""

import sounddevice as sd
import numpy as np
import keyboard
import pyperclip
import time
import json
import os
import sys
import re
import platform
import subprocess
import threading
import ctypes
from pathlib import Path
from faster_whisper import WhisperModel
from scipy.io.wavfile import write as wav_write
import tempfile

import pystray
from PIL import Image, ImageDraw

try:
    import winsound
    HAS_WINSOUND = True
except ImportError:
    HAS_WINSOUND = False

# ============ CONFIGURATION ============
DEFAULT_CONFIG = {
    "hotkey": "f15",
    "pause_hotkey": "f14",
    "language": None,
    "model": "auto",
    "compute_type": "auto",
    "device": "auto",
    "enable_punctuation": True,
    "enable_formatting": True,
    "enable_capitalization": True,
    "max_line_length": 80,
    "output_mode": "type",
    "sample_rate": 16000,
    "audio_threshold": 0.01,
    "min_duration": 0.5,
    "input_method": "unicode", # Options: unicode, keyboard, clipboard
    "auto_minimize_console": True,
    "sound_feedback": True,
    "initial_prompt": None,
    "beam_size": 5,
    "best_of": 5,
    "temperature": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],
    "condition_on_previous_text": True,
    "repetition_penalty": 1.1,
    "no_repeat_ngram_size": 3,
    "no_speech_threshold": 0.6,
    "log_prob_threshold": -1.0,
    "compression_ratio_threshold": 2.4,
    "hallucination_silence_threshold": 1.0,
    "vad_filter": True,
    "vad_parameters": {
        "threshold": 0.5,
        "min_silence_duration_ms": 300,
        "min_speech_duration_ms": 250,
        "max_speech_duration_s": 30
    },
    "user_profile": {
        "name": "",
        "primary_language": "auto",
        "formality": "casual",
        "common_phrases": []
    }
}

CONFIG_FILE = "config.json"
DEVICE_PROFILE_FILE = "device-profile.json"

# Language detection patterns
ENGLISH_PATTERN = re.compile(r'^[a-zA-Z\s\.,!?;:\-\'"()[\]{}]+$')
CHINESE_PATTERN = re.compile(r'[\u4e00-\u9fff]')

# ============ WINDOWS INPUT API ============
if platform.system() == "Windows":
    import ctypes
    from ctypes import wintypes

    user32 = ctypes.WinDLL('user32', use_last_error=True)

    INPUT_KEYBOARD = 1
    KEYEVENTF_UNICODE = 0x0004
    KEYEVENTF_KEYUP = 0x0002

    class KEYBDINPUT(ctypes.Structure):
        _fields_ = [
            ("wVk", wintypes.WORD),
            ("wScan", wintypes.WORD),
            ("dwFlags", wintypes.DWORD),
            ("time", wintypes.DWORD),
            ("dwExtraInfo", ctypes.c_size_t),
        ]

    class MOUSEINPUT(ctypes.Structure):
        _fields_ = [
            ("dx", wintypes.LONG),
            ("dy", wintypes.LONG),
            ("mouseData", wintypes.DWORD),
            ("dwFlags", wintypes.DWORD),
            ("time", wintypes.DWORD),
            ("dwExtraInfo", ctypes.c_size_t),
        ]

    class HARDWAREINPUT(ctypes.Structure):
        _fields_ = [
            ("uMsg", wintypes.DWORD),
            ("wParamL", wintypes.WORD),
            ("wParamH", wintypes.WORD),
        ]

    class INPUT_u(ctypes.Union):
        _fields_ = [("ki", KEYBDINPUT), ("mi", MOUSEINPUT), ("hi", HARDWAREINPUT)]

    class INPUT(ctypes.Structure):
        _fields_ = [("type", wintypes.DWORD), ("u", INPUT_u)]

    def send_unicode_input(text, delay=0.01):
        """Send Unicode text input using low-level Windows API."""
        if not text:
            return
        for char in text:
            code = ord(char)
            # UTF-16 surrogate pairs support
            if code > 0xFFFF:
                # High surrogate
                h = 0xD800 + ((code - 0x10000) >> 10)
                # Low surrogate
                l = 0xDC00 + ((code - 0x10000) & 0x3FF)
                _send_unicode_char(h)
                _send_unicode_char(l)
            else:
                _send_unicode_char(code)
            
            # Vital for some apps to process the event
            time.sleep(delay)

    def _send_unicode_char(code):
        # Key down
        inputs = (INPUT * 2)()
        inputs[0].type = INPUT_KEYBOARD
        inputs[0].u.ki.wVk = 0
        inputs[0].u.ki.wScan = code
        inputs[0].u.ki.dwFlags = KEYEVENTF_UNICODE
        
        # Key up
        inputs[1].type = INPUT_KEYBOARD
        inputs[1].u.ki.wVk = 0
        inputs[1].u.ki.wScan = code
        inputs[1].u.ki.dwFlags = KEYEVENTF_UNICODE | KEYEVENTF_KEYUP
        
        user32.SendInput(2, ctypes.byref(inputs), ctypes.sizeof(INPUT))
else:
    def send_unicode_input(text):
        keyboard.write(text)
# ======================================

class DeviceProfiler:
    """Ëá™Âä®Ê£ÄÊµãËÆæÂ§áËÉΩÂäõÂπ∂Êé®ËçêÊúÄ‰Ω≥ÈÖçÁΩÆ"""
    
    @staticmethod
    def detect_gpu():
        """Ê£ÄÊµãGPUÁ±ªÂûãÂíåËÉΩÂäõ"""
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                return {
                    "available": True,
                    "name": gpu_name,
                    "vram_gb": vram_gb,
                    "cuda_version": torch.version.cuda,
                    "compute_capability": torch.cuda.get_device_capability(0)
                }
        except:
            pass
        return {"available": False, "name": "CPU Only", "vram_gb": 0}
    
    @staticmethod
    def detect_audio_devices():
        """Ê£ÄÊµãÂèØÁî®Èü≥È¢ëËÆæÂ§á"""
        try:
            devices = sd.query_devices()
            input_devices = [d for d in devices if d['max_input_channels'] > 0]
            return {
                "count": len(input_devices),
                "default": sd.query_devices(kind='input'),
                "all": input_devices
            }
        except:
            return {"count": 0, "default": None, "all": []}
    
    @staticmethod
    def recommend_config(gpu_info):
        """Ê†πÊçÆÁ°¨‰ª∂Êé®ËçêÈÖçÁΩÆ"""
        if not gpu_info["available"]:
            return {
                "model": "base",
                "compute_type": "int8",
                "device": "cpu",
                "beam_size": 3,
                "note": "Running in CPU mode. Consider using 'tiny' or 'base' model for better speed."
            }
        
        vram = gpu_info["vram_gb"]
        
        if vram >= 10:  # High-end GPU (RTX 4070+, 3080+)
            return {
                "model": "large-v3",
                "compute_type": "float16",
                "device": "cuda",
                "beam_size": 5,
                "note": "High-performance mode activated. Best accuracy for mixed Chinese-English."
            }
        elif vram >= 5:  # Mid-range GPU (RTX 3060, 2060)
            return {
                "model": "medium",
                "compute_type": "float16",
                "device": "cuda",
                "beam_size": 5,
                "note": "Balanced mode. Good accuracy with reasonable speed."
            }
        elif vram >= 2:  # Entry GPU (GTX 1650, etc.)
            return {
                "model": "small",
                "compute_type": "int8",
                "device": "cuda",
                "beam_size": 3,
                "note": "Economy GPU mode. Consider 'base' model for better accuracy."
            }
        else:  # Low VRAM or integrated graphics
            return {
                "model": "base",
                "compute_type": "int8",
                "device": "cuda",
                "beam_size": 3,
                "note": "Low VRAM mode. Using quantized model."
            }
    
    @staticmethod
    def create_profile():
        """ÂàõÂª∫ËÆæÂ§áÈÖçÁΩÆÊñá‰ª∂"""
        print("üîç Analyzing your system...")
        
        gpu_info = DeviceProfiler.detect_gpu()
        audio_info = DeviceProfiler.detect_audio_devices()
        recommendations = DeviceProfiler.recommend_config(gpu_info)
        
        profile = {
            "system": {
                "platform": platform.system(),
                "python_version": platform.python_version(),
            },
            "gpu": gpu_info,
            "audio": audio_info,
            "recommendations": recommendations,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Save device profile
        with open(DEVICE_PROFILE_FILE, 'w', encoding='utf-8') as f:
            json.dump(profile, f, indent=2, ensure_ascii=False)
        
        return profile


class SmartFormatter:
    """Universal Text Formatter - Chinese & English"""
    
    # Chinese punctuation rules
    CN_PARTICLES = {
        'Âïä': 'ÔºÅ', 'ÂëÄ': 'ÔºÅ', 'Âìá': 'ÔºÅ', 'Âï¶': 'ÔºÅ', 'Âë¢': 'Ôºü', 
        'Âêß': 'Ôºü', 'Âêó': 'Ôºü', '‰πà': 'Ôºü', 'Âòõ': 'ÔºÅ', 'Âì¶': '„ÄÇ', 'ËØ∂': 'Ôºå',
    }
    
    CN_SENTENCE_STARTERS = ['È¶ñÂÖà', 'ÂÖ∂Ê¨°', 'ÁÑ∂Âêé', 'Êé•ÁùÄ', 'ÊúÄÂêé', 'ÊÄª‰πã', 'ÊâÄ‰ª•', 'Âõ†Ê≠§', '‰ΩÜÊòØ', 'ÁÑ∂ËÄå', '‰∏çËøá', 'Á¨¨‰∏Ä', 'Á¨¨‰∫å', 'Á¨¨‰∏â']
    CN_CONNECTORS = ['ËÄå‰∏î', 'Âπ∂‰∏î', 'ÊàñËÄÖ', 'ËøòÊòØ', 'Âõ†‰∏∫', 'Áî±‰∫é', 'ËôΩÁÑ∂', 'Â∞ΩÁÆ°']
    
    # English formatting rules
    EN_SENTENCE_ENDERS = ['.', '!', '?']
    EN_COMMON_ABBREVIATIONS = ['Mr.', 'Mrs.', 'Dr.', 'Prof.', 'Inc.', 'Ltd.', 'Jr.', 'Sr.', 'vs.', 'etc.', 'i.e.', 'e.g.']
    
    @staticmethod
    def detect_language(text):
        """Ê£ÄÊµãÊñáÊú¨‰∏ªË¶ÅËØ≠Ë®Ä"""
        cn_chars = len(CHINESE_PATTERN.findall(text))
        en_chars = len(re.findall(r'[a-zA-Z]', text))
        
        if cn_chars > en_chars:
            return 'chinese' if cn_chars > 5 else 'mixed'
        elif en_chars > cn_chars:
            return 'english' if en_chars > 5 else 'mixed'
        return 'mixed'
    
    @staticmethod
    def format_text(text, lang=None, enable_punct=True, enable_format=True, enable_cap=True):
        """Universal text formatting"""
        if not text:
            return text
        
        if lang is None:
            lang = SmartFormatter.detect_language(text)
        
        original = text.strip()
        
        # Step 1: Add punctuation
        if enable_punct:
            if lang in ['chinese', 'mixed']:
                text = SmartFormatter.add_chinese_punctuation(text)
            if lang in ['english', 'mixed']:
                text = SmartFormatter.add_english_punctuation(text)
        
        # Step 2: Capitalization (English)
        if enable_cap and lang in ['english', 'mixed']:
            text = SmartFormatter.capitalize_english(text)
        
        # Step 3: Layout formatting
        if enable_format:
            text = SmartFormatter.format_layout(text, lang)
        
        return text
    
    @staticmethod
    def add_chinese_punctuation(text):
        """Add punctuation for Chinese text"""
        if not CHINESE_PATTERN.search(text):
            return text
        
        # Check if already has sufficient punctuation
        cn_chars = len(CHINESE_PATTERN.findall(text))
        punct_count = len(re.findall(r'[Ôºå„ÄÇÔºüÔºÅÔºõÔºö]', text))
        if cn_chars > 0 and punct_count >= cn_chars / 15:
            return text
        
        # Add particles punctuation
        for particle, punct in SmartFormatter.CN_PARTICLES.items():
            pattern = f'{particle}(?![Ôºå„ÄÇÔºüÔºÅ,\.?!])'
            text = re.sub(pattern, f'{particle}{punct}', text)
        
        # Add sentence starter punctuation
        for starter in SmartFormatter.CN_SENTENCE_STARTERS:
            pattern = f'(?<![Ôºå„ÄÇÔºüÔºÅ,\.?!\n]){starter}'
            text = re.sub(pattern, f'„ÄÇ{starter}', text)
        
        # Add connector punctuation
        for connector in SmartFormatter.CN_CONNECTORS:
            pattern = f'(?<![Ôºå„ÄÇÔºüÔºÅ,\.?!\n]){connector}'
            text = re.sub(pattern, f'Ôºå{connector}', text)
        
        # Clean and finalize
        text = SmartFormatter.clean_punctuation(text)
        
        if text and text[-1] not in 'Ôºå„ÄÇÔºüÔºÅ,\.?!':
            text += '„ÄÇ'
        
        return text
    
    @staticmethod
    def add_english_punctuation(text):
        """Add punctuation for English text"""
        if not re.search(r'[a-zA-Z]', text):
            return text
        
        # Check if already has sufficient punctuation
        sentences = len(re.findall(r'[a-zA-Z][\.!?]', text))
        words = len(re.findall(r'[a-zA-Z]+', text))
        if words > 0 and sentences >= words / 20:
            return text
        
        # Split into potential sentences
        parts = re.split(r'(\s+(?:and|but|or|so|because|however|therefore|moreover|furthermore)\s+)', text, flags=re.IGNORECASE)
        
        result = []
        for i, part in enumerate(parts):
            if not part.strip():
                result.append(part)
                continue
            
            # Check if it's a connector
            if re.match(r'^\s+(?:and|but|or)\s+$', part, re.IGNORECASE) and i > 0:
                # Add comma before connector if not present
                if result and not result[-1].rstrip()[-1:] in '.,!?;:': 
                    result[-1] = result[-1].rstrip() + ','
                result.append(part)
            elif re.match(r'^\s+(?:so|because|however|therefore)\s+$', part, re.IGNORECASE) and i > 0:
                # Stronger separation for these
                if result and not result[-1].rstrip()[-1:] in '.!?':
                    result[-1] = result[-1].rstrip() + '.'
                result.append(part)
            else:
                result.append(part)
        
        text = ''.join(result)
        
        # Ensure sentence ends with punctuation
        text = text.strip()
        if text and text[-1] not in '.!?':
            # Check if it ends with abbreviation
            if not any(text.endswith(abbr) for abbr in SmartFormatter.EN_COMMON_ABBREVIATIONS):
                text += '.'
        
        return text
    
    @staticmethod
    def capitalize_english(text):
        """Smart capitalization for English"""
        # Split into sentences
        sentences = re.split(r'([.!?]\s+)', text)
        result = []
        
        for i, sent in enumerate(sentences):
            if not sent.strip():
                result.append(sent)
                continue
            
            # Check if this is a separator
            if re.match(r'^[.!?]\s+$', sent):
                result.append(sent)
                continue
            
            # Capitalize first letter of sentence
            words = sent.split()
            if words:
                words[0] = words[0].capitalize()
                
                # Capitalize 'I'
                words = ['I' if w.lower() == 'i' and (i == 0 or not w.isupper()) else w for w in words]
                
                result.append(' '.join(words))
            else:
                result.append(sent)
        
        return ''.join(result)
    
    @staticmethod
    def format_layout(text, lang='mixed', max_length=80):
        """Format layout for readability"""
        if not text:
            return text
        
        # Optimize spacing between languages
        text = SmartFormatter.optimize_spacing(text)
        
        # Paragraph segmentation
        text = SmartFormatter.paragraph_segmentation(text, lang)
        
        # Line breaking for long text
        text = SmartFormatter.break_long_lines(text, max_length)
        
        # Clean up
        text = re.sub(r'  +', ' ', text)
        text = re.sub(r'\n\n\n+', '\n\n', text)
        
        return text.strip()
    
    @staticmethod
    def optimize_spacing(text):
        """Optimize spacing between Chinese and English"""
        # Add space between Chinese and English/numbers
        text = re.sub(r'([\u4e00-\u9fff])([a-zA-Z0-9])', r'\1 \2', text)
        text = re.sub(r'([a-zA-Z0-9])([\u4e00-\u9fff])', r'\1 \2', text)
        
        # Clean multiple spaces
        text = re.sub(r'  +', ' ', text)
        
        return text
    
    @staticmethod
    def paragraph_segmentation(text, lang):
        """Segment into paragraphs"""
        # Chinese paragraph markers
        cn_markers = ['È¶ñÂÖà', 'ÂÖ∂Ê¨°', 'Á¨¨‰∏Ä', 'Á¨¨‰∫å', 'Á¨¨‰∏â', 'ÊúÄÂêé', 'ÊÄªÁªì', 'ÊÄª‰πã', 'Áªº‰∏ä']
        # English paragraph markers
        en_markers = ['First', 'Second', 'Third', 'Finally', 'In conclusion', 'To summarize', 'Overall']
        
        markers = cn_markers if lang == 'chinese' else en_markers if lang == 'english' else cn_markers + en_markers
        
        for marker in markers:
            pattern = rf'(?<!^)(?<![\n])\s*{marker}\b'
            text = re.sub(pattern, f'\n{marker}', text)
        
        return text
    
    @staticmethod
    def break_long_lines(text, max_length):
        """Break long lines for readability"""
        lines = text.split('\n')
        result = []
        
        for line in lines:
            if len(line) <= max_length:
                result.append(line)
                continue
            
            # Break at sentence boundaries
            sentences = re.split(r'([.!?„ÄÇÔºÅÔºü])', line)
            current = ""
            
            for sent in sentences:
                if len(current) + len(sent) > max_length and current:
                    result.append(current)
                    current = sent
                else:
                    current += sent
            
            if current:
                result.append(current)
        
        return '\n'.join(result)
    
    @staticmethod
    def clean_punctuation(text):
        """Clean duplicate and misplaced punctuation"""
        # Merge duplicate punctuation
        text = re.sub(r'[Ôºå,]{2,}', 'Ôºå', text)
        text = re.sub(r'[„ÄÇ.]{2,}', '„ÄÇ', text)
        text = re.sub(r'[ÔºÅ!]{2,}', 'ÔºÅ', text)
        text = re.sub(r'[Ôºü?]{2,}', 'Ôºü', text)
        
        # Fix sequences
        text = re.sub(r'Ôºå„ÄÇ', '„ÄÇ', text)
        text = re.sub(r'„ÄÇÔºå', '„ÄÇ', text)
        
        return text


class SetupWizard:
    """Setup wizard for non-technical users"""
    
    @staticmethod
    def run():
        """Interactive setup"""
        print("\n" + "="*60)
        print("üéØ Welcome to Universal Whisper Dictation Setup")
        print("="*60)
        
        config = DEFAULT_CONFIG.copy()
        
        # Device detection
        print("\nüìä Step 1: Device Detection")
        profile = DeviceProfiler.create_profile()
        
        gpu_info = profile["gpu"]
        if gpu_info["available"]:
            print(f"   ‚úì GPU detected: {gpu_info['name']}")
            print(f"   ‚úì VRAM: {gpu_info['vram_gb']:.1f} GB")
        else:
            print("   ‚ÑπÔ∏è No GPU detected, will use CPU mode")
        
        rec = profile["recommendations"]
        print(f"\n   Recommended: {rec['model']} model ({rec['note']})")
        
        # Apply recommendations
        config["model"] = rec["model"]
        config["compute_type"] = rec["compute_type"]
        config["device"] = rec["device"]
        
        # User preferences
        print("\nüé® Step 2: Personal Preferences")
        
        # Primary language
        print("\n   Primary language usage:")
        print("   1. Chinese (‰∏≠Êñá)")
        print("   2. English")
        print("   3. Mixed (Chinese + English)")
        print("   4. Auto-detect")
        choice = input("   Select (1-4) [4]: ").strip() or "4"
        lang_map = {"1": "zh", "2": "en", "3": "mixed", "4": "auto"}
        config["user_profile"]["primary_language"] = lang_map.get(choice, "auto")
        
        # Formality
        print("\n   Text style:")
        print("   1. Casual (ÈÄÇÂêàËÅäÂ§©„ÄÅÊó•Â∏∏)")
        print("   2. Formal (ÈÄÇÂêàÂ∑•‰ΩúÈÇÆ‰ª∂)")
        print("   3. Business (ÈÄÇÂêàÂïÜÂä°Âú∫ÊôØ)")
        choice = input("   Select (1-3) [1]: ").strip() or "1"
        formality_map = {"1": "casual", "2": "formal", "3": "business"}
        config["user_profile"]["formality"] = formality_map.get(choice, "casual")
        
        # Hotkey
        print("\n‚å®Ô∏è  Step 3: Hotkey Configuration")
        print("   Recommended for mouse buttons: F15, F16, F17, F18, F19, F20")
        print("   Other options: ctrl+shift+d, insert, pause")
        hotkey = input(f"   Enter hotkey [{config['hotkey']}]: ").strip()
        if hotkey:
            config["hotkey"] = hotkey
        
        # Features
        print("\n‚öôÔ∏è  Step 4: Features")
        
        punct = input("   Enable auto-punctuation? (y/n) [y]: ").strip().lower()
        config["enable_punctuation"] = punct != 'n'
        
        fmt = input("   Enable smart formatting? (y/n) [y]: ").strip().lower()
        config["enable_formatting"] = fmt != 'n'
        
        cap = input("   Enable auto-capitalization? (y/n) [y]: ").strip().lower()
        config["enable_capitalization"] = cap != 'n'
        
        # Output mode
        print("\nüì§ Step 5: Output Mode")
        print("   1. Type directly into active window")
        print("   2. Copy to clipboard only")
        print("   3. Both type and copy to clipboard")
        choice = input("   Select (1-3) [1]: ").strip() or "1"
        mode_map = {"1": "type", "2": "clipboard", "3": "both"}
        config["output_mode"] = mode_map.get(choice, "type")
        
        # Save configuration
        print("\nüíæ Saving configuration...")
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print("\n" + "="*60)
        print("‚úÖ Setup complete!")
        print("="*60)
        print(f"\nConfiguration saved to: {CONFIG_FILE}")
        print(f"Device profile saved to: {DEVICE_PROFILE_FILE}")
        print("\nYou can run the setup again anytime by deleting these files.")
        print("\nPress Enter to start dictation...")
        input()
        
        return config


class WhisperDictation:
    """Main dictation class with system tray lifecycle.

    Lifecycle:
        Start ‚Üí Tray icon (‚úÖ Ready) ‚Üí Console minimizes
        Hold F15 ‚Üí üî¥ Recording ‚Üí Release ‚Üí Transcribe ‚Üí ‚úÖ Ready
        F14 (or tray) ‚Üí ‚è∏ Paused ‚Üî ‚úÖ Ready
        Tray "Exit" ‚Üí Graceful shutdown
    """

    # Tray icon states
    STATE_READY = "ready"
    STATE_RECORDING = "recording"
    STATE_PROCESSING = "processing"
    STATE_PAUSED = "paused"

    def __init__(self, config):
        self.config = config
        self.is_recording = False
        self.is_paused = False
        self.audio_buffer = []
        self.stream = None
        self.formatter = SmartFormatter()
        self.model = None
        self.tray = None
        self._stop_event = threading.Event()
        self._state = self.STATE_READY
        self._last_audio_callback_time = time.time()
        self._stream_error_count = 0

        # Load all settings from config
        self._load_config(config)

        self._print_banner()
        self._load_model()

    def _load_config(self, config: dict):
        """Load all settings from config dict."""
        # Hotkeys
        self.hotkey = config.get("hotkey", "f15")
        self.pause_hotkey = config.get("pause_hotkey", "f14")

        # Model & device
        self.language = config.get("language")
        self.model_size = config.get("model", "base")
        self.compute_type = config.get("compute_type", "int8")
        self.device = config.get("device", "cpu")

        # Text processing
        self.enable_punct = config.get("enable_punctuation", True)
        self.enable_format = config.get("enable_formatting", True)
        self.enable_cap = config.get("enable_capitalization", True)
        self.max_line_length = config.get("max_line_length", 80)

        # Output & audio
        self.output_mode = config.get("output_mode", "type")
        self.input_method = config.get("input_method", "unicode")
        self.sample_rate = config.get("sample_rate", 16000)
        self.audio_threshold = config.get("audio_threshold", 0.01)
        self.min_duration = config.get("min_duration", 0.5)
        self.auto_minimize = config.get("auto_minimize_console", True)
        self.sound_feedback = config.get("sound_feedback", True)
        self.initial_prompt = config.get("initial_prompt")
        self.user_profile = config.get("user_profile", {})

        # Transcription (advanced)
        self.beam_size = config.get("beam_size", 5)
        self.best_of = config.get("best_of", 5)
        self.temperature = config.get("temperature", [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])
        self.condition_on_prev = config.get("condition_on_previous_text", True)
        self.repetition_penalty = config.get("repetition_penalty", 1.1)
        self.no_repeat_ngram_size = config.get("no_repeat_ngram_size", 3)

        # Quality thresholds
        self.no_speech_threshold = config.get("no_speech_threshold", 0.6)
        self.log_prob_threshold = config.get("log_prob_threshold", -1.0)
        self.compression_ratio_threshold = config.get("compression_ratio_threshold", 2.4)
        self.hallucination_silence_threshold = config.get("hallucination_silence_threshold", 1.0)

        # VAD
        self.vad_filter = config.get("vad_filter", True)
        self.vad_parameters = config.get("vad_parameters", {
            "threshold": 0.5,
            "min_silence_duration_ms": 300,
            "min_speech_duration_ms": 250,
            "max_speech_duration_s": 30
        })

    # ---- Tray icon helpers ----

    @staticmethod
    def _create_icon_image(color: str, size: int = 64) -> Image.Image:
        """Create a solid circle icon with the given color."""
        img = Image.new("RGBA", (size, size), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        margin = 4
        draw.ellipse([margin, margin, size - margin, size - margin], fill=color)
        return img

    def _update_tray_state(self, state: str):
        """Update tray icon and tooltip to reflect current state."""
        self._state = state
        color_map = {
            self.STATE_READY: ("#22c55e", "Whisper Dictation ‚Äî Ready"),       # green
            self.STATE_RECORDING: ("#ef4444", "Whisper Dictation ‚Äî Recording..."),  # red
            self.STATE_PROCESSING: ("#f59e0b", "Whisper Dictation ‚Äî Processing..."), # amber
            self.STATE_PAUSED: ("#a3a3a3", "Whisper Dictation ‚Äî Paused"),      # gray
        }
        color, tooltip = color_map.get(state, ("#22c55e", "Whisper Dictation"))
        if self.tray:
            self.tray.icon = self._create_icon_image(color)
            self.tray.title = tooltip
            # Rebuild menu to reflect pause/resume label
            self.tray.menu = self._build_menu()

    def _build_menu(self) -> pystray.Menu:
        """Build the tray right-click menu."""
        pause_label = "Resume" if self.is_paused else "Pause"
        return pystray.Menu(
            pystray.MenuItem(pause_label, self._on_toggle_pause),
            pystray.MenuItem("Settings...", self._on_settings),
            pystray.Menu.SEPARATOR,
            pystray.MenuItem("Exit", self._on_exit),
        )

    def _on_toggle_pause(self, icon=None, item=None):
        """Toggle pause/resume."""
        self.is_paused = not self.is_paused
        if self.is_paused:
            print("‚è∏  Paused ‚Äî hotkey disabled")
            self._update_tray_state(self.STATE_PAUSED)
        else:
            print(f"‚úÖ Resumed ‚Äî hold '{self.hotkey.upper()}' to dictate")
            self._update_tray_state(self.STATE_READY)

    def _on_exit(self, icon=None, item=None):
        """Graceful shutdown from tray."""
        print("\nüëã Shutting down...")
        self._stop_event.set()
        if self.tray:
            self.tray.stop()

    def _on_settings(self, icon=None, item=None):
        """open settings GUI as subprocess."""
        try:
            # Launch settings_gui.py in a separate process
            # This avoids threading conflicts with tkinter
            cmd = [sys.executable, "settings_gui.py"]
            self._settings_process = subprocess.Popen(cmd, cwd=os.path.dirname(os.path.abspath(__file__)))
            
            # Start a thread to wait for it to close, then reload config
            threading.Thread(target=self._monitor_settings, daemon=True).start()
        except Exception as e:
            print(f"‚ùå Failed to launch settings: {e}")

    def _monitor_settings(self):
        """Wait for settings process to close, then reload config."""
        if hasattr(self, '_settings_process'):
            self._settings_process.wait()
            # Reload config
            try:
                if os.path.exists(CONFIG_FILE):
                    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                        new_config = json.load(f)
                    self._apply_config(new_config)
            except Exception as e:
                print(f"‚ùå Failed to reload config: {e}")

    def _apply_config(self, new_config: dict):
        """Apply new config values live (where possible)."""
        self.config = new_config
        self._load_config(new_config)
        print("‚öôÔ∏è  Settings updated (model/device changes need restart)")

    # ---- Startup ----

    def _print_banner(self):
        """Print startup banner."""
        print("\n" + "="*60)
        print("üé§ Universal Whisper Dictation")
        print("="*60)
        print(f"\nüìã Configuration:")
        print(f"   Hotkey: {self.hotkey.upper()}")
        print(f"   Pause:  {self.pause_hotkey.upper()}")
        print(f"   Model:  {self.model_size}")
        print(f"   Device: {self.device.upper()}")
        print(f"   Language: {self.language or 'Auto-detect'}")
        print(f"   Punctuation: {'‚úì' if self.enable_punct else '‚úó'}")
        print(f"   Formatting:  {'‚úì' if self.enable_format else '‚úó'}")
        print(f"   Capitals:    {'‚úì' if self.enable_cap else '‚úó'}")
        print(f"   Output: {self.output_mode}")
        print("\n" + "-"*60)
        print(f"üéØ Controls:")
        print(f"   HOLD '{self.hotkey.upper()}' ‚Üí Speak ‚Üí RELEASE to transcribe")
        print(f"   Press '{self.pause_hotkey.upper()}' to pause/resume")
        print(f"   Right-click tray icon ‚Üí Exit")
        print("-"*60 + "\n")

    def _load_model(self):
        """Load Whisper model."""
        print(f"‚è≥ Loading {self.model_size} model...")
        print("   (First run may download model files)")

        try:
            self.model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type
            )
            print(f"‚úÖ Model loaded successfully!\n")
        except Exception as e:
            print(f"‚ùå Failed to load model: {e}")
            print("   Falling back to CPU mode with base model...")
            self.model = WhisperModel("base", device="cpu", compute_type="int8")
            print(f"‚úÖ Fallback model loaded!\n")

    # ---- Recording ----

    def audio_callback(self, indata, frames, time_info, status):
        """Audio capture callback."""
        self._last_audio_callback_time = time.time()
        if status:
            self._stream_error_count += 1
            if self._stream_error_count <= 3:
                print(f"‚ö†Ô∏è  Audio stream warning: {status}")
        if self.is_recording:
            self._callbacks_during_recording += 1
            self.audio_buffer.append(indata.copy())

    def _play_beep(self, freq: int = 800, duration_ms: int = 100):
        """Play a short beep sound for feedback."""
        if self.sound_feedback and HAS_WINSOUND:
            try:
                threading.Thread(
                    target=winsound.Beep, args=(freq, duration_ms), daemon=True
                ).start()
            except Exception:
                pass

    def start_recording(self):
        """Handle hotkey press: Start or Toggle Stop."""
        # If currently paused, ignore or resume? For now, ignore if paused (use F14 to resume)
        if self.is_paused:
            return

        # Smart Latch Logic:
        # 1. If NOT recording: Start recording.
        # 2. If recording and WAS LATCHED (tapped previously): Stop recording.
        # 3. If recording and NOT latched (currently holding): Ignore (key repeat).

        if not self.is_recording:
            # --- START RECORDING ---
            self.audio_buffer = []
            self._recording_start_time = time.time()
            self._callbacks_during_recording = 0
            self.is_recording = True
            self.is_latched = False  # Default to PTT mode, upgrade to latched if released quickly
            
            self._update_tray_state(self.STATE_RECORDING)
            self._play_beep(800, 80)
            print("üî¥ Recording... (speak now)")
        
        elif self.is_latched:
            # --- STOP RECORDING (Toggle off) ---
            self.stop_recording(force=True)

    def stop_recording(self, force=False):
        """Handle hotkey release: Check for Latch or Stop."""
        if not self.is_recording:
            return

        # If this is a forced stop (from press-to-toggle-off), execute stop.
        if force:
            pass  # Proceed to stop
        
        # If currently latched, release event means nothing (user lifted finger after toggle-off press? 
        # No, wait. If latched, the 'press' stops it. The 'release' shouldn't do anything.)
        elif self.is_latched:
            return

        # If NOT latched (normal PTT state), check hold duration
        else:
            hold_duration = time.time() - self._recording_start_time
            
            # If held less than 0.3s, treat as TAP -> LATCH ON (Toggle Mode)
            # This failsafe also handles games that force immediate release events (~0.01s)
            if hold_duration < 0.3:
                self.is_latched = True
                print(f"   üîí Latched Mode (Tap to stop)")
                return
            
            # Otherwise, normal PTT stop
            pass

        # --- EXECUTE STOP ---
        self.is_recording = False
        self.is_latched = False
        
        # Diagnostics
        hold_duration = time.time() - self._recording_start_time
        cb_count = self._callbacks_during_recording
        # print(f"   ‚è± Held {hold_duration:.3f}s / {cb_count} callbacks") # Debug only

        self._update_tray_state(self.STATE_PROCESSING)
        time.sleep(0.1)

        if not self.audio_buffer:
            print("‚ö†Ô∏è  No audio captured\n")
            self._update_tray_state(self.STATE_READY)
            return

        threading.Thread(target=self._process_recording, daemon=True).start()

    def _process_recording(self):
        """Process captured audio (runs in background thread)."""
        audio_data = np.concatenate(self.audio_buffer, axis=0)
        duration = len(audio_data) / self.sample_rate

        if duration < self.min_duration:
            print(f"‚ö†Ô∏è  Recording too short ({duration:.1f}s)\n")
            self._update_tray_state(self.STATE_READY)
            return

        print(f"‚è≥ Processing {duration:.1f}s...", end=" ")

        temp_path = os.path.join(tempfile.gettempdir(), "dictation_temp.wav")

        try:
            wav_write(temp_path, self.sample_rate, (audio_data * 32767).astype(np.int16))

            self._play_beep(600, 80)  # Lower beep = processing

            # Build transcription options from config
            vad_params = dict(self.vad_parameters)
            vad_params["max_speech_duration_s"] = max(
                vad_params.get("max_speech_duration_s", 30),
                duration + 1
            )

            options = {
                "beam_size": self.beam_size,
                "best_of": self.best_of,
                "temperature": self.temperature,
                "condition_on_previous_text": self.condition_on_prev,
                "repetition_penalty": self.repetition_penalty,
                "no_repeat_ngram_size": self.no_repeat_ngram_size,
                "no_speech_threshold": self.no_speech_threshold,
                "log_prob_threshold": self.log_prob_threshold,
                "compression_ratio_threshold": self.compression_ratio_threshold,
                "language": self.language,
                "vad_filter": self.vad_filter,
                "vad_parameters": vad_params,
            }

            if self.hallucination_silence_threshold:
                options["hallucination_silence_threshold"] = self.hallucination_silence_threshold

            if self.initial_prompt:
                options["initial_prompt"] = self.initial_prompt

            segments, info = self.model.transcribe(temp_path, **options)
            text = " ".join([segment.text.strip() for segment in segments])

            if text:
                lang = self.formatter.detect_language(text)
                formatted = self.formatter.format_text(
                    text,
                    lang=lang,
                    enable_punct=self.enable_punct,
                    enable_format=self.enable_format,
                    enable_cap=self.enable_cap
                )

                print(f"‚úì Done")
                print(f"   Original: {text[:60]}{'...' if len(text) > 60 else ''}")
                if formatted != text:
                    print(f"   Formatted: {formatted[:60]}{'...' if len(formatted) > 60 else ''}")

                self._output_text(formatted)
                print()
            else:
                print("‚ö†Ô∏è  No speech detected\n")

        except Exception as e:
            print(f"‚ùå Error: {e}\n")

        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            self._update_tray_state(self.STATE_READY)

    def _output_text(self, text):
        """Output text according to mode."""
        if self.output_mode in ["clipboard", "both"]:
            pyperclip.copy(text)

        if self.output_mode in ["type", "both"]:
            # Replace newlines with spaces to avoid triggering Enter
            # in chat apps (Slack, Teams, WeChat, etc.)
            safe_text = text.replace("\n\n", " ").replace("\n", " ")
            time.sleep(0.05)
            
            if self.input_method == "unicode":
                send_unicode_input(safe_text)
            elif self.input_method == "clipboard":
                # Fallback to pasting if the app supports it better
                pyperclip.copy(safe_text)
                keyboard.press_and_release('ctrl+v')
            else:
                # Default legacy method
                keyboard.write(safe_text)

    # ---- Main loop ----

    def _open_audio_stream(self):
        """Open (or reopen) the audio input stream in shared mode."""
        if self.stream is not None:
            try:
                self.stream.stop()
                self.stream.close()
            except Exception:
                pass

        base_kwargs = {
            "samplerate": self.sample_rate,
            "channels": 1,
            "callback": self.audio_callback,
            "blocksize": 1024,
        }

        # Strategy: try WASAPI shared mode first (best for games),
        # fall back to default if device doesn't support WASAPI.
        attempts = []
        try:
            wasapi = sd.WasapiSettings(exclusive=False)
            attempts.append(("WASAPI shared mode", {**base_kwargs, "extra_settings": wasapi}))
        except Exception:
            pass  # WasapiSettings not available
        attempts.append(("default mode", base_kwargs))

        for label, kwargs in attempts:
            try:
                self.stream = sd.InputStream(**kwargs)
                self.stream.start()
                self._last_audio_callback_time = time.time()
                self._stream_error_count = 0
                print(f"   üé§ Audio stream opened ({label})")
                return True
            except Exception as e:
                print(f"   ‚ö†Ô∏è  {label} failed: {e}")

        print("‚ùå All audio stream modes failed.")
        return False

    def _stream_watchdog(self):
        """Monitor audio stream health; restart if it dies."""
        TIMEOUT = 5  # seconds of silence before restart
        while not self._stop_event.is_set():
            self._stop_event.wait(3)  # check every 3 seconds
            if self._stop_event.is_set():
                break
            elapsed = time.time() - self._last_audio_callback_time
            if elapsed > TIMEOUT:
                print(f"\n‚ö†Ô∏è  Audio stream appears dead ({elapsed:.0f}s no callbacks). Restarting...")
                if self._open_audio_stream():
                    print("‚úÖ Audio stream restarted successfully.")
                else:
                    print("‚ùå Audio stream restart failed. Will retry...")

    def _hook_watchdog(self):
        """Monitor keyboard hooks and re-register only if they stop working."""
        # Don't aggressively unhook_all ‚Äî it disrupts press-hold-release cycles.
        # Instead, just monitor. If hooks stop working, the user will notice
        # and can restart the app.
        pass  # Disabled: aggressive rehooking causes more harm than good

    def _run_dictation_loop(self):
        """Dictation engine running in a background thread."""
        if not self._open_audio_stream():
            print("‚ùå Cannot start without audio. Exiting.")
            self._stop_event.set()
            return

        # Start watchdog threads
        threading.Thread(target=self._stream_watchdog, daemon=True).start()
        threading.Thread(target=self._hook_watchdog, daemon=True).start()

        try:
            keyboard.on_press_key(self.hotkey, lambda _: self.start_recording())
            keyboard.on_release_key(self.hotkey, lambda _: self.stop_recording())
            keyboard.on_press_key(self.pause_hotkey, lambda _: self._on_toggle_pause())

            print(f"‚úÖ Ready! Hold '{self.hotkey.upper()}' to dictate...")
            print(f"   Press '{self.pause_hotkey.upper()}' to pause/resume")
            print(f"   Right-click tray icon ‚Üí Exit\n")

            # Wait until stop event is set (from tray Exit)
            self._stop_event.wait()

        finally:
            keyboard.unhook_all()
            if self.stream:
                self.stream.stop()
                self.stream.close()

        print("üëã Goodbye!")

    def run(self):
        """Start the app with system tray icon."""
        # Start dictation in background thread
        engine_thread = threading.Thread(target=self._run_dictation_loop, daemon=True)
        engine_thread.start()

        # Create and run system tray (blocks on main thread)
        self.tray = pystray.Icon(
            "whisper-dictation",
            self._create_icon_image("#22c55e"),
            "Whisper Dictation ‚Äî Ready",
            menu=self._build_menu(),
        )
        self.tray.run()  # blocks until tray.stop() is called

        # Ensure engine thread stops
        self._stop_event.set()
        engine_thread.join(timeout=3)


def test_microphone():
    """Test microphone"""
    print("üé§ Testing microphone...")
    print("   Please speak for 3 seconds...")
    
    try:
        recording = sd.rec(int(3 * 16000), samplerate=16000, channels=1, dtype='float32')
        sd.wait()
        
        max_val = np.max(np.abs(recording))
        
        if max_val > 0.01:
            print(f"   ‚úì Microphone working! Level: {max_val:.3f}\n")
            return True
        else:
            print("   ‚ö†Ô∏è  Microphone level too low\n")
            return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}\n")
        return False


def load_or_setup_config():
    """Load existing config or run setup"""
    # Check for existing config
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"‚úì Loaded configuration from {CONFIG_FILE}")
            return config
        except:
            pass
    
    # Run setup wizard
    return SetupWizard.run()


def hide_console_window():
    """Minimize the console window to system tray area."""
    try:
        hwnd = ctypes.windll.kernel32.GetConsoleWindow()
        if hwnd:
            ctypes.windll.user32.ShowWindow(hwnd, 6)  # SW_MINIMIZE = 6
    except Exception:
        pass


def is_admin():
    try:
        return ctypes.windll.shell32.IsUserAnAdmin()
    except:
        return False

def main():
    """Main entry point."""
    if not is_admin():
        print("\n‚ö†Ô∏è  WARNING: Not running as Administrator")
        print("   Dictation might NOT work in some games or apps (e.g. Task Manager, Fluent Search).")
        print("   Please right-click the script/bat and select 'Run as Administrator' if you have issues.\n")
        time.sleep(2)

    try:
        config = load_or_setup_config()

        if not test_microphone():
            print("‚ö†Ô∏è  Microphone check failed.")
            print("   This might be a false alarm if you were silent.")
            choice = input("   Continue anyway? (y/n) [y]: ").strip().lower()
            if choice == 'n':
                return

        app = WhisperDictation(config)

        if config.get("auto_minimize_console", True):
            hide_console_window()

        app.run()

    except KeyboardInterrupt:
        print("\nüëã Goodbye!")
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
        input("\nPress Enter to exit...")


if __name__ == "__main__":
    main()
